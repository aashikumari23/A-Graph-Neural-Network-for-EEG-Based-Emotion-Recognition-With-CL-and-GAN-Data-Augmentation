{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDkJD6my_iCf",
        "outputId": "aa6eeb95-49f1-4002-9df3-7901c51dbbd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class DEAPDataLoader:\n",
        "    \"\"\"\n",
        "    Loader for DEAP dataset preprocessed data\n",
        "\n",
        "    The DEAP dataset should be in the preprocessed format (.dat files)\n",
        "    Download from: http://www.eecs.qmul.ac.uk/mmv/datasets/deap/\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_path):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path: Path to the folder containing s01.dat, s02.dat, etc.\n",
        "        \"\"\"\n",
        "        self.data_path = Path(data_path)\n",
        "\n",
        "    def load_subject_data(self, subject_id):\n",
        "        \"\"\"\n",
        "        Load data for a single subject\n",
        "\n",
        "        Args:\n",
        "            subject_id: Subject number (1-32)\n",
        "\n",
        "        Returns:\n",
        "            data: EEG data (40 trials, 40 channels, 8064 timepoints)\n",
        "            labels: Labels (40 trials, 4 dimensions: valence, arousal, dominance, liking)\n",
        "        \"\"\"\n",
        "        filename = self.data_path / f's{subject_id:02d}.dat'\n",
        "\n",
        "        if not filename.exists():\n",
        "            raise FileNotFoundError(f\"File not found: {filename}\")\n",
        "\n",
        "        with open(filename, 'rb') as f:\n",
        "            subject = pickle.load(f, encoding='latin1')\n",
        "\n",
        "        # subject is a dict with keys: 'data' and 'labels'\n",
        "        # data shape: (40 trials, 40 channels, 8064 timepoints)\n",
        "        # labels shape: (40 trials, 4) - [valence, arousal, dominance, liking]\n",
        "\n",
        "        return subject['data'], subject['labels']\n",
        "\n",
        "    def load_all_subjects(self, n_subjects=32):\n",
        "        \"\"\"\n",
        "        Load data from all subjects\n",
        "\n",
        "        Args:\n",
        "            n_subjects: Number of subjects to load (default: 32)\n",
        "\n",
        "        Returns:\n",
        "            all_data: EEG data (n_subjects*40 trials, 40 channels, 8064 timepoints)\n",
        "            all_labels: Labels (n_subjects*40 trials, 4)\n",
        "            subject_ids: Subject ID for each trial\n",
        "        \"\"\"\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "        subject_ids = []\n",
        "\n",
        "        print(f\"Loading DEAP data for {n_subjects} subjects...\")\n",
        "\n",
        "        for subject_id in range(1, n_subjects + 1):\n",
        "            try:\n",
        "                data, labels = self.load_subject_data(subject_id)\n",
        "                all_data.append(data)\n",
        "                all_labels.append(labels)\n",
        "                subject_ids.extend([subject_id] * len(data))\n",
        "\n",
        "                if subject_id % 10 == 0:\n",
        "                    print(f\"Loaded {subject_id}/{n_subjects} subjects\")\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Warning: Subject {subject_id} data not found, skipping...\")\n",
        "                continue\n",
        "\n",
        "        all_data = np.vstack(all_data)\n",
        "        all_labels = np.vstack(all_labels)\n",
        "        subject_ids = np.array(subject_ids)\n",
        "\n",
        "        print(f\"Total loaded: {len(all_data)} trials\")\n",
        "        print(f\"Data shape: {all_data.shape}\")\n",
        "        print(f\"Labels shape: {all_labels.shape}\")\n",
        "\n",
        "        return all_data, all_labels, subject_ids\n",
        "\n",
        "    def preprocess_for_model(self, data, labels, use_32_channels=True):\n",
        "        \"\"\"\n",
        "        Preprocess DEAP data for the emotion recognition model\n",
        "\n",
        "        Args:\n",
        "            data: Raw DEAP data (trials, 40 channels, 8064 timepoints)\n",
        "            labels: DEAP labels (trials, 4) - continuous values 1-9\n",
        "            use_32_channels: Use only EEG channels (first 32), exclude EOG\n",
        "\n",
        "        Returns:\n",
        "            X: Preprocessed EEG (trials, channels, timepoints)\n",
        "            y_valence: Binary valence labels (0=low, 1=high)\n",
        "            y_arousal: Binary arousal labels (0=low, 1=high)\n",
        "        \"\"\"\n",
        "        # Use only EEG channels (first 32), remove EOG and peripheral channels\n",
        "        if use_32_channels:\n",
        "            X = data[:, :32, :]\n",
        "        else:\n",
        "            X = data\n",
        "\n",
        "        # Keep only 60 seconds (remove 3s baseline already removed in preprocessed data)\n",
        "        # 8064 timepoints = 63s * 128Hz, we want 60s = 7680 timepoints\n",
        "        X = X[:, :, :7680]\n",
        "\n",
        "        # Extract valence and arousal labels\n",
        "        valence = labels[:, 0]  # First column\n",
        "        arousal = labels[:, 1]  # Second column\n",
        "\n",
        "        # Convert to binary classification (threshold at 5)\n",
        "        # Ratings 1-5 = low (0), ratings 6-9 = high (1)\n",
        "        y_valence = (valence > 5).astype(np.int32)\n",
        "        y_arousal = (arousal > 5).astype(np.int32)\n",
        "\n",
        "        print(f\"\\nPreprocessed data shape: {X.shape}\")\n",
        "        print(f\"Valence distribution: Low={np.sum(y_valence==0)}, High={np.sum(y_valence==1)}\")\n",
        "        print(f\"Arousal distribution: Low={np.sum(y_arousal==0)}, High={np.sum(y_arousal==1)}\")\n",
        "\n",
        "        return X, y_valence, y_arousal\n",
        "\n",
        "    def split_train_test(self, X, y_valence, y_arousal, subject_ids=None,\n",
        "                        test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Split data into train and test sets\n",
        "\n",
        "        Args:\n",
        "            X: EEG data\n",
        "            y_valence, y_arousal: Labels\n",
        "            subject_ids: Optional subject IDs for subject-independent split\n",
        "            test_size: Fraction for test set\n",
        "            random_state: Random seed\n",
        "\n",
        "        Returns:\n",
        "            X_train, X_test, y_valence_train, y_valence_test,\n",
        "            y_arousal_train, y_arousal_test\n",
        "        \"\"\"\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        if subject_ids is None:\n",
        "            # Random split\n",
        "            indices = np.arange(len(X))\n",
        "            train_idx, test_idx = train_test_split(\n",
        "                indices, test_size=test_size, random_state=random_state,\n",
        "                stratify=y_valence  # Stratify by valence\n",
        "            )\n",
        "        else:\n",
        "            # Subject-independent split (some subjects in train, others in test)\n",
        "            unique_subjects = np.unique(subject_ids)\n",
        "            n_test_subjects = int(len(unique_subjects) * test_size)\n",
        "\n",
        "            np.random.seed(random_state)\n",
        "            test_subjects = np.random.choice(\n",
        "                unique_subjects, n_test_subjects, replace=False\n",
        "            )\n",
        "\n",
        "            test_idx = np.where(np.isin(subject_ids, test_subjects))[0]\n",
        "            train_idx = np.where(~np.isin(subject_ids, test_subjects))[0]\n",
        "\n",
        "        X_train = X[train_idx]\n",
        "        X_test = X[test_idx]\n",
        "        y_valence_train = y_valence[train_idx]\n",
        "        y_valence_test = y_valence[test_idx]\n",
        "        y_arousal_train = y_arousal[train_idx]\n",
        "        y_arousal_test = y_arousal[test_idx]\n",
        "\n",
        "        print(f\"\\nTrain set: {len(X_train)} trials\")\n",
        "        print(f\"Test set: {len(X_test)} trials\")\n",
        "\n",
        "        return (X_train, X_test, y_valence_train, y_valence_test,\n",
        "                y_arousal_train, y_arousal_test)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# USAGE EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Example of how to load DEAP data and prepare it for the model\n",
        "    \"\"\"\n",
        "\n",
        "    # STEP 1: Set your DEAP data path\n",
        "    # Download from: http://www.eecs.qmul.ac.uk/mmv/datasets/deap/\n",
        "    # You need the \"Preprocessed data (Python)\" version\n",
        "    DEAP_PATH = \"/content/drive/My Drive/deap-dataset/data_preprocessed_python\"\n",
        "\n",
        "    # Check if path exists\n",
        "    if not os.path.exists(DEAP_PATH):\n",
        "        print(f\"ERROR: DEAP data path not found: {DEAP_PATH}\")\n",
        "        print(\"\\nPlease:\")\n",
        "        print(\"1. Download DEAP dataset from: http://www.eecs.qmul.ac.uk/mmv/datasets/deap/\")\n",
        "        print(\"2. Extract the 'data_preprocessed_python' folder\")\n",
        "        print(\"3. Update DEAP_PATH variable above with the correct path\")\n",
        "        return\n",
        "\n",
        "    # STEP 2: Load the data\n",
        "    loader = DEAPDataLoader(DEAP_PATH)\n",
        "\n",
        "    # Load all subjects (32 subjects, 40 trials each = 1280 total trials)\n",
        "    all_data, all_labels, subject_ids = loader.load_all_subjects(n_subjects=32)\n",
        "\n",
        "    # STEP 3: Preprocess for the model\n",
        "    X, y_valence, y_arousal = loader.preprocess_for_model(all_data, all_labels)\n",
        "\n",
        "    # STEP 4: Split into train/test\n",
        "    # Option A: Random split (80/20)\n",
        "    X_train, X_test, y_val_train, y_val_test, y_ar_train, y_ar_test = \\\n",
        "        loader.split_train_test(X, y_valence, y_arousal, test_size=0.2)\n",
        "\n",
        "    # Option B: Subject-independent split (uncomment to use)\n",
        "    # X_train, X_test, y_val_train, y_val_test, y_ar_train, y_ar_test = \\\n",
        "    #     loader.split_train_test(X, y_valence, y_arousal, subject_ids, test_size=0.2)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA READY FOR TRAINING!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "    # STEP 5: Now you can use the emotion recognition model\n",
        "    print(\"\\nTo train the model, use:\")\n",
        "    print(\"from emotion_recognition import EEGEmotionRecognition\")\n",
        "    print(\"model = EEGEmotionRecognition(n_channels=32)\")\n",
        "    print(\"model.train(X_train, y_val_train, y_ar_train, augment_factor=1.0)\")\n",
        "    print(\"valence_pred, arousal_pred = model.predict(X_test)\")\n",
        "\n",
        "    return X_train, X_test, y_val_train, y_val_test, y_ar_train, y_ar_test\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the example\n",
        "    data = main()\n",
        "\n",
        "    # If data loaded successfully, you can continue with training\n",
        "    if data is not None:\n",
        "        X_train, X_test, y_val_train, y_val_test, y_ar_train, y_ar_test = data\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Next step: Train the model (this takes a while!)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Uncomment below to actually train\n",
        "        # from emotion_recognition import EEGEmotionRecognition\n",
        "        # model = EEGEmotionRecognition(n_channels=32)\n",
        "        # model.train(X_train, y_val_train, y_ar_train, augment_factor=1.0)\n",
        "        # valence_pred, arousal_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkvoPRleIXHM",
        "outputId": "38ae32d7-820a-45f8-b34c-6fd5643b7295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DEAP data for 32 subjects...\n",
            "Loaded 10/32 subjects\n",
            "Loaded 20/32 subjects\n",
            "Loaded 30/32 subjects\n",
            "Total loaded: 1280 trials\n",
            "Data shape: (1280, 40, 8064)\n",
            "Labels shape: (1280, 4)\n",
            "\n",
            "Preprocessed data shape: (1280, 32, 7680)\n",
            "Valence distribution: Low=1011, High=269\n",
            "Arousal distribution: Low=982, High=298\n",
            "\n",
            "Train set: 1024 trials\n",
            "Test set: 256 trials\n",
            "\n",
            "============================================================\n",
            "DATA READY FOR TRAINING!\n",
            "============================================================\n",
            "X_train shape: (1024, 32, 7680)\n",
            "X_test shape: (256, 32, 7680)\n",
            "\n",
            "To train the model, use:\n",
            "from emotion_recognition import EEGEmotionRecognition\n",
            "model = EEGEmotionRecognition(n_channels=32)\n",
            "model.train(X_train, y_val_train, y_ar_train, augment_factor=1.0)\n",
            "valence_pred, arousal_pred = model.predict(X_test)\n",
            "\n",
            "============================================================\n",
            "Next step: Train the model (this takes a while!)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(Counter(y_val_train))\n",
        "print(Counter(y_ar_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZzDUPwyNoWu",
        "outputId": "cc9e4ce5-c19f-4f08-ca1d-235b3118c2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({np.int32(0): 809, np.int32(1): 215})\n",
            "Counter({np.int32(0): 785, np.int32(1): 239})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Optimized CL module and training (loss < 2) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Encoder returns (batch, 32, 70)\n",
        "class ChannelEncoder(nn.Module):\n",
        "    def __init__(self, n_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=7, stride=4, padding=3)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 32, kernel_size=7, stride=4, padding=3)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.conv3 = nn.Conv1d(32, 32, kernel_size=7, stride=4, padding=3)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return x  # (B,32,70)\n",
        "\n",
        "# Projector: pools over time -> linear -> proj_dim\n",
        "class ContrastiveProjector(nn.Module):\n",
        "    def __init__(self, in_ch=32, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_ch, proj_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(proj_dim, proj_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, feat_map):\n",
        "        pooled = feat_map.mean(dim=2)   # (B,32)\n",
        "        proj = self.fc(pooled)          # (B,proj_dim)\n",
        "        proj = F.normalize(proj, dim=1)\n",
        "        return proj\n",
        "\n",
        "class ContrastiveLearning(nn.Module):\n",
        "    def __init__(self, n_channels=32, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = ChannelEncoder(n_channels)\n",
        "        self.projector = ContrastiveProjector(in_ch=32, proj_dim=proj_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat_map = self.encoder(x)\n",
        "        proj = self.projector(feat_map)\n",
        "        return feat_map, proj\n",
        "\n",
        "# NT-Xent loss (cross-entropy over similarities)\n",
        "def nt_xent_loss(z1, z2, temperature=0.1):\n",
        "    assert z1.shape == z2.shape\n",
        "    B = z1.shape[0]\n",
        "    z = torch.cat([z1, z2], dim=0)              # (2B, D)\n",
        "    sim = torch.matmul(z, z.T) / temperature\n",
        "    labels = torch.arange(B, device=z.device)\n",
        "    labels = torch.cat([labels + B, labels])\n",
        "\n",
        "    # mask self-similarity\n",
        "    large_neg = -1e9\n",
        "    sim_masked = sim.clone()\n",
        "    idx = torch.arange(2*B, device=z.device)\n",
        "    sim_masked[idx, idx] = large_neg\n",
        "\n",
        "    loss = F.cross_entropy(sim_masked, labels)\n",
        "    return loss\n",
        "\n",
        "# Strong EEG augmentations\n",
        "def eeg_augment(x, noise_std=0.05, shift_max=500, scale_range=(0.8,1.2), dropout_prob=0.1):\n",
        "    B, C, T = x.shape\n",
        "    out = x.clone()\n",
        "\n",
        "    # Gaussian noise\n",
        "    out = out + torch.randn_like(out) * noise_std\n",
        "\n",
        "    # Circular shift\n",
        "    shifts = torch.randint(-shift_max, shift_max+1, (B,))\n",
        "    for i, s in enumerate(shifts):\n",
        "        out[i] = torch.roll(out[i], shifts=s.item(), dims=1)\n",
        "\n",
        "    # Random scaling\n",
        "    scales = torch.rand(B,1,1, device=x.device) * (scale_range[1]-scale_range[0]) + scale_range[0]\n",
        "    out = out * scales\n",
        "\n",
        "    # Random channel dropout\n",
        "    mask = torch.rand(B, C, 1, device=x.device) > dropout_prob\n",
        "    out = out * mask.float()\n",
        "\n",
        "    return out\n",
        "\n",
        "# ----------------- Prepare data -----------------\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "X_test_tensor  = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "# ----------------- Training CL -----------------\n",
        "cl_model = ContrastiveLearning(n_channels=32, proj_dim=128).to(device)\n",
        "optimizer_cl = torch.optim.Adam(cl_model.parameters(), lr=3e-3)  # slightly higher lr\n",
        "batch_size = 64   # increase if GPU allows\n",
        "epochs_cl = 120   # train longer\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "cl_model.train()\n",
        "for epoch in range(epochs_cl):\n",
        "    total_loss = 0.0\n",
        "    for (x_batch,) in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        x1 = eeg_augment(x_batch)\n",
        "        x2 = eeg_augment(x_batch)\n",
        "\n",
        "        _, z1 = cl_model(x1)\n",
        "        _, z2 = cl_model(x2)\n",
        "\n",
        "        loss = nt_xent_loss(z1, z2, temperature=0.1)  # sharper softmax\n",
        "        optimizer_cl.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_cl.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"[CL] Epoch {epoch+1}/{epochs_cl}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# ----------------- Extract features for GAN -----------------\n",
        "cl_model.eval()\n",
        "with torch.no_grad():\n",
        "    train_feat_maps = cl_model.encoder(X_train_tensor)   # (N,32,70)\n",
        "    test_feat_maps  = cl_model.encoder(X_test_tensor)\n",
        "\n",
        "train_features = train_feat_maps.cpu().numpy()\n",
        "test_features  = test_feat_maps.cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgw-2C9vLGPg",
        "outputId": "254c9278-93f8-41b3-8d1d-259f83953f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CL] Epoch 1/120, Loss: 2.3683\n",
            "[CL] Epoch 2/120, Loss: 1.3686\n",
            "[CL] Epoch 3/120, Loss: 1.2453\n",
            "[CL] Epoch 4/120, Loss: 1.1069\n",
            "[CL] Epoch 5/120, Loss: 1.0564\n",
            "[CL] Epoch 6/120, Loss: 0.9989\n",
            "[CL] Epoch 7/120, Loss: 0.9627\n",
            "[CL] Epoch 8/120, Loss: 0.8745\n",
            "[CL] Epoch 9/120, Loss: 0.8410\n",
            "[CL] Epoch 10/120, Loss: 0.8031\n",
            "[CL] Epoch 11/120, Loss: 0.7794\n",
            "[CL] Epoch 12/120, Loss: 0.7482\n",
            "[CL] Epoch 13/120, Loss: 0.6413\n",
            "[CL] Epoch 14/120, Loss: 0.6085\n",
            "[CL] Epoch 15/120, Loss: 0.5920\n",
            "[CL] Epoch 16/120, Loss: 0.5907\n",
            "[CL] Epoch 17/120, Loss: 0.5752\n",
            "[CL] Epoch 18/120, Loss: 0.5621\n",
            "[CL] Epoch 19/120, Loss: 0.4992\n",
            "[CL] Epoch 20/120, Loss: 0.4843\n",
            "[CL] Epoch 21/120, Loss: 0.4826\n",
            "[CL] Epoch 22/120, Loss: 0.5088\n",
            "[CL] Epoch 23/120, Loss: 0.5104\n",
            "[CL] Epoch 24/120, Loss: 0.4354\n",
            "[CL] Epoch 25/120, Loss: 0.3915\n",
            "[CL] Epoch 26/120, Loss: 0.4029\n",
            "[CL] Epoch 27/120, Loss: 0.3519\n",
            "[CL] Epoch 28/120, Loss: 0.3712\n",
            "[CL] Epoch 29/120, Loss: 0.3720\n",
            "[CL] Epoch 30/120, Loss: 0.4444\n",
            "[CL] Epoch 31/120, Loss: 0.3290\n",
            "[CL] Epoch 32/120, Loss: 0.3759\n",
            "[CL] Epoch 33/120, Loss: 0.4046\n",
            "[CL] Epoch 34/120, Loss: 0.3535\n",
            "[CL] Epoch 35/120, Loss: 0.3362\n",
            "[CL] Epoch 36/120, Loss: 0.3226\n",
            "[CL] Epoch 37/120, Loss: 0.3560\n",
            "[CL] Epoch 38/120, Loss: 0.3463\n",
            "[CL] Epoch 39/120, Loss: 0.3072\n",
            "[CL] Epoch 40/120, Loss: 0.3056\n",
            "[CL] Epoch 41/120, Loss: 0.2954\n",
            "[CL] Epoch 42/120, Loss: 0.2965\n",
            "[CL] Epoch 43/120, Loss: 0.3169\n",
            "[CL] Epoch 44/120, Loss: 0.3056\n",
            "[CL] Epoch 45/120, Loss: 0.2923\n",
            "[CL] Epoch 46/120, Loss: 0.3082\n",
            "[CL] Epoch 47/120, Loss: 0.2666\n",
            "[CL] Epoch 48/120, Loss: 0.2571\n",
            "[CL] Epoch 49/120, Loss: 0.2856\n",
            "[CL] Epoch 50/120, Loss: 0.2459\n",
            "[CL] Epoch 51/120, Loss: 0.2538\n",
            "[CL] Epoch 52/120, Loss: 0.2535\n",
            "[CL] Epoch 53/120, Loss: 0.2451\n",
            "[CL] Epoch 54/120, Loss: 0.2292\n",
            "[CL] Epoch 55/120, Loss: 0.2207\n",
            "[CL] Epoch 56/120, Loss: 0.2363\n",
            "[CL] Epoch 57/120, Loss: 0.2622\n",
            "[CL] Epoch 58/120, Loss: 0.2335\n",
            "[CL] Epoch 59/120, Loss: 0.2339\n",
            "[CL] Epoch 60/120, Loss: 0.2223\n",
            "[CL] Epoch 61/120, Loss: 0.2209\n",
            "[CL] Epoch 62/120, Loss: 0.2267\n",
            "[CL] Epoch 63/120, Loss: 0.2187\n",
            "[CL] Epoch 64/120, Loss: 0.2149\n",
            "[CL] Epoch 65/120, Loss: 0.1925\n",
            "[CL] Epoch 66/120, Loss: 0.2000\n",
            "[CL] Epoch 67/120, Loss: 0.2081\n",
            "[CL] Epoch 68/120, Loss: 0.2101\n",
            "[CL] Epoch 69/120, Loss: 0.2130\n",
            "[CL] Epoch 70/120, Loss: 0.1809\n",
            "[CL] Epoch 71/120, Loss: 0.1775\n",
            "[CL] Epoch 72/120, Loss: 0.1889\n",
            "[CL] Epoch 73/120, Loss: 0.1871\n",
            "[CL] Epoch 74/120, Loss: 0.2241\n",
            "[CL] Epoch 75/120, Loss: 0.2087\n",
            "[CL] Epoch 76/120, Loss: 0.1905\n",
            "[CL] Epoch 77/120, Loss: 0.2302\n",
            "[CL] Epoch 78/120, Loss: 0.1827\n",
            "[CL] Epoch 79/120, Loss: 0.2351\n",
            "[CL] Epoch 80/120, Loss: 0.2056\n",
            "[CL] Epoch 81/120, Loss: 0.2009\n",
            "[CL] Epoch 82/120, Loss: 0.1900\n",
            "[CL] Epoch 83/120, Loss: 0.2127\n",
            "[CL] Epoch 84/120, Loss: 0.1955\n",
            "[CL] Epoch 85/120, Loss: 0.2049\n",
            "[CL] Epoch 86/120, Loss: 0.2044\n",
            "[CL] Epoch 87/120, Loss: 0.1707\n",
            "[CL] Epoch 88/120, Loss: 0.1802\n",
            "[CL] Epoch 89/120, Loss: 0.2331\n",
            "[CL] Epoch 90/120, Loss: 0.1800\n",
            "[CL] Epoch 91/120, Loss: 0.1953\n",
            "[CL] Epoch 92/120, Loss: 0.1966\n",
            "[CL] Epoch 93/120, Loss: 0.1769\n",
            "[CL] Epoch 94/120, Loss: 0.1793\n",
            "[CL] Epoch 95/120, Loss: 0.1904\n",
            "[CL] Epoch 96/120, Loss: 0.1684\n",
            "[CL] Epoch 97/120, Loss: 0.1882\n",
            "[CL] Epoch 98/120, Loss: 0.1690\n",
            "[CL] Epoch 99/120, Loss: 0.1698\n",
            "[CL] Epoch 100/120, Loss: 0.1670\n",
            "[CL] Epoch 101/120, Loss: 0.1826\n",
            "[CL] Epoch 102/120, Loss: 0.1770\n",
            "[CL] Epoch 103/120, Loss: 0.1854\n",
            "[CL] Epoch 104/120, Loss: 0.1638\n",
            "[CL] Epoch 105/120, Loss: 0.1815\n",
            "[CL] Epoch 106/120, Loss: 0.1887\n",
            "[CL] Epoch 107/120, Loss: 0.1802\n",
            "[CL] Epoch 108/120, Loss: 0.1852\n",
            "[CL] Epoch 109/120, Loss: 0.1624\n",
            "[CL] Epoch 110/120, Loss: 0.1750\n",
            "[CL] Epoch 111/120, Loss: 0.1823\n",
            "[CL] Epoch 112/120, Loss: 0.1872\n",
            "[CL] Epoch 113/120, Loss: 0.1559\n",
            "[CL] Epoch 114/120, Loss: 0.1532\n",
            "[CL] Epoch 115/120, Loss: 0.1497\n",
            "[CL] Epoch 116/120, Loss: 0.1848\n",
            "[CL] Epoch 117/120, Loss: 0.1500\n",
            "[CL] Epoch 118/120, Loss: 0.1413\n",
            "[CL] Epoch 119/120, Loss: 0.1617\n",
            "[CL] Epoch 120/120, Loss: 0.1640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ======================================================\n",
        "#  Improved Generator & Discriminator (Conditioned)\n",
        "# ======================================================\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, code_dim=256, n_classes=2, out_channels=32, out_time=120, hidden_dim=1024):\n",
        "        super().__init__()\n",
        "        # Combine noise + label embedding\n",
        "        self.label_emb = nn.Embedding(n_classes, code_dim)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(code_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(hidden_dim, out_channels * out_time),\n",
        "            nn.Tanh()  # normalize outputs between [-1,1]\n",
        "        )\n",
        "        self.out_channels = out_channels\n",
        "        self.out_time = out_time\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        # Add label info to noise\n",
        "        label_embed = self.label_emb(labels)\n",
        "        x = z + label_embed\n",
        "        out = self.net(x)\n",
        "        return out.view(-1, self.out_channels, self.out_time)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=32, in_time=120, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv1d(in_channels, 64, kernel_size=3, padding=1)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.utils.spectral_norm(nn.Conv1d(64, 128, kernel_size=3, padding=1)),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.conv(x))\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "#  Training Function (Stabilized)\n",
        "# ======================================================\n",
        "def train_gan_for_class(real_samples, class_label,\n",
        "                        code_dim=256, n_classes=2,\n",
        "                        batch_size=64, epochs=150, d_steps=5, lr=2e-4):\n",
        "    \"\"\"Train a class-conditioned GAN for one emotion class.\"\"\"\n",
        "    real_tensor = torch.tensor(real_samples, dtype=torch.float32)\n",
        "    loader = DataLoader(TensorDataset(real_tensor), batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    G = Generator(code_dim, n_classes).to(device)\n",
        "    D = Discriminator(n_classes=n_classes).to(device)\n",
        "\n",
        "    opt_G = torch.optim.Adam(G.parameters(), lr=lr * 1.5, betas=(0.5, 0.9))  # generator slightly faster\n",
        "    opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.9))\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        d_loss_total, g_loss_total = 0, 0\n",
        "        for (x_real,) in loader:\n",
        "            x_real = x_real.to(device)\n",
        "            B = x_real.size(0)\n",
        "            y_real = torch.ones((B, 1), device=device)\n",
        "            y_fake = torch.zeros((B, 1), device=device)\n",
        "\n",
        "            # --------------------\n",
        "            # Train Discriminator\n",
        "            # --------------------\n",
        "            for _ in range(d_steps):\n",
        "                z = torch.randn(B, code_dim, device=device)\n",
        "                labels = torch.full((B,), class_label, dtype=torch.long, device=device)\n",
        "                fake = G(z, labels).detach()\n",
        "\n",
        "                opt_D.zero_grad()\n",
        "                loss_real = criterion(D(x_real), y_real)\n",
        "                loss_fake = criterion(D(fake), y_fake)\n",
        "                loss_d = (loss_real + loss_fake) / 2\n",
        "                loss_d.backward()\n",
        "                opt_D.step()\n",
        "                d_loss_total += loss_d.item()\n",
        "\n",
        "            # --------------------\n",
        "            # Train Generator\n",
        "            # --------------------\n",
        "            z = torch.randn(B, code_dim, device=device)\n",
        "            labels = torch.full((B,), class_label, dtype=torch.long, device=device)\n",
        "            opt_G.zero_grad()\n",
        "            fake = G(z, labels)\n",
        "            loss_g = criterion(D(fake), y_real)\n",
        "            loss_g.backward()\n",
        "            opt_G.step()\n",
        "            g_loss_total += loss_g.item()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"[Class {class_label}] Epoch {epoch+1}/{epochs} | D_loss={d_loss_total/len(loader):.4f} | G_loss={g_loss_total/len(loader):.4f}\")\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "#  Generation Function (Minority Boost)\n",
        "# ======================================================\n",
        "def generate_synthetic_for_class(G, n_samples, class_label, code_dim=256):\n",
        "    G.eval()\n",
        "    synth = []\n",
        "    with torch.no_grad():\n",
        "        bs = min(256, n_samples)\n",
        "        for _ in range(int(np.ceil(n_samples / bs))):\n",
        "            z = torch.randn(bs, code_dim, device=device)\n",
        "            labels = torch.full((bs,), class_label, dtype=torch.long, device=device)\n",
        "            x_fake = G(z, labels).cpu().numpy()\n",
        "            synth.append(x_fake)\n",
        "    synth = np.vstack(synth)[:n_samples]\n",
        "    return synth\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "#  Augmentation Wrapper\n",
        "# ======================================================\n",
        "def classwise_gan_augment(X_train, y_train, balance_mode='equalize', code_dim=256, epochs=150):\n",
        "    counts = Counter(y_train)\n",
        "    majority = max(counts.values())\n",
        "\n",
        "    X_synth_all, y_synth_all = [], []\n",
        "    for c in np.unique(y_train):\n",
        "        real_c = X_train[y_train == c]\n",
        "        if balance_mode == 'equalize':\n",
        "            target = majority - len(real_c)\n",
        "            if c == 1:\n",
        "                target = int(target * 1.25)  # generate 50% more synthetic \"High\"\n",
        "\n",
        "        else:\n",
        "            target = len(real_c)\n",
        "        if target <= 0:\n",
        "            continue\n",
        "        print(f\"\\n Training GAN for class {c}: real={len(real_c)}, synth_target={target}\")\n",
        "        G = train_gan_for_class(real_c, class_label=c, code_dim=code_dim, epochs=epochs)\n",
        "        synth = generate_synthetic_for_class(G, target, class_label=c, code_dim=code_dim)\n",
        "        X_synth_all.append(synth)\n",
        "        y_synth_all.append(np.full(target, c, dtype=np.int32))\n",
        "\n",
        "    if X_synth_all:\n",
        "        X_aug = np.vstack([X_train] + X_synth_all)\n",
        "        y_aug = np.concatenate([y_train] + y_synth_all)\n",
        "    else:\n",
        "        X_aug, y_aug = X_train, y_train\n",
        "\n",
        "    print(\"\\n Class counts after augmentation:\", Counter(y_aug))\n",
        "    return X_aug, y_aug\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  MAIN EXECUTION â€” use CL feature maps\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- GAN augmentation on CL embeddings ---\")\n",
        "\n",
        "    # use your precomputed embeddings from CL\n",
        "    X_train_feat = train_features      # (N, 32, 70)\n",
        "    y_train_val = y_val_train          # valence labels\n",
        "    y_train_ar = y_ar_train            # arousal labels\n",
        "\n",
        "    # --- GAN for Valence ---\n",
        "    print(\"\\n Training GANs for Valence balancing...\")\n",
        "    X_val_aug, y_val_aug = classwise_gan_augment(X_train_feat, y_train_val,\n",
        "                                                 balance_mode='equalize',\n",
        "                                                 code_dim=256, epochs=200)\n",
        "\n",
        "    # --- GAN for Arousal ---\n",
        "    print(\"\\n Training GANs for Arousal balancing...\")\n",
        "    X_ar_aug, y_ar_aug = classwise_gan_augment(X_train_feat, y_train_ar,\n",
        "                                               balance_mode='equalize',\n",
        "                                               code_dim=256, epochs=150)\n",
        "\n",
        "    # Save augmented feature maps for GNN\n",
        "    np.savez(\"deap_gan_augmented_features.npz\",\n",
        "             X_val=X_val_aug, y_val=y_val_aug,\n",
        "             X_ar=X_ar_aug, y_ar=y_ar_aug)\n",
        "\n",
        "    print(\"\\n GAN augmentation finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN5FMXgUHzy_",
        "outputId": "4a6fe185-c4cb-407b-d886-fe6e59e95992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GAN augmentation on CL embeddings ---\n",
            "\n",
            " Training GANs for Valence balancing...\n",
            "\n",
            " Training GAN for class 1: real=215, synth_target=742\n",
            "[Class 1] Epoch 10/200 | D_loss=3.2482 | G_loss=0.7642\n",
            "[Class 1] Epoch 20/200 | D_loss=3.1044 | G_loss=0.8062\n",
            "[Class 1] Epoch 30/200 | D_loss=3.1297 | G_loss=0.8489\n",
            "[Class 1] Epoch 40/200 | D_loss=2.6221 | G_loss=0.9977\n",
            "[Class 1] Epoch 50/200 | D_loss=2.6401 | G_loss=0.9992\n",
            "[Class 1] Epoch 60/200 | D_loss=2.3523 | G_loss=1.1057\n",
            "[Class 1] Epoch 70/200 | D_loss=2.2555 | G_loss=1.1919\n",
            "[Class 1] Epoch 80/200 | D_loss=2.1229 | G_loss=1.1811\n",
            "[Class 1] Epoch 90/200 | D_loss=2.0378 | G_loss=1.2530\n",
            "[Class 1] Epoch 100/200 | D_loss=1.8396 | G_loss=1.3144\n",
            "[Class 1] Epoch 110/200 | D_loss=1.7173 | G_loss=1.4474\n",
            "[Class 1] Epoch 120/200 | D_loss=1.6560 | G_loss=1.5958\n",
            "[Class 1] Epoch 130/200 | D_loss=1.5043 | G_loss=1.6613\n",
            "[Class 1] Epoch 140/200 | D_loss=1.3899 | G_loss=1.5354\n",
            "[Class 1] Epoch 150/200 | D_loss=1.2476 | G_loss=2.0324\n",
            "[Class 1] Epoch 160/200 | D_loss=1.1689 | G_loss=2.1379\n",
            "[Class 1] Epoch 170/200 | D_loss=1.0472 | G_loss=1.8739\n",
            "[Class 1] Epoch 180/200 | D_loss=1.0158 | G_loss=2.2556\n",
            "[Class 1] Epoch 190/200 | D_loss=0.9514 | G_loss=2.0157\n",
            "[Class 1] Epoch 200/200 | D_loss=0.8924 | G_loss=2.2172\n",
            "\n",
            " Class counts after augmentation: Counter({np.int32(1): 957, np.int32(0): 809})\n",
            "\n",
            " Training GANs for Arousal balancing...\n",
            "\n",
            " Training GAN for class 1: real=239, synth_target=682\n",
            "[Class 1] Epoch 10/150 | D_loss=3.2431 | G_loss=0.7813\n",
            "[Class 1] Epoch 20/150 | D_loss=2.9359 | G_loss=0.9726\n",
            "[Class 1] Epoch 30/150 | D_loss=2.8727 | G_loss=0.9709\n",
            "[Class 1] Epoch 40/150 | D_loss=2.5374 | G_loss=1.0476\n",
            "[Class 1] Epoch 50/150 | D_loss=2.1968 | G_loss=1.1631\n",
            "[Class 1] Epoch 60/150 | D_loss=2.1652 | G_loss=1.2958\n",
            "[Class 1] Epoch 70/150 | D_loss=1.8826 | G_loss=1.4339\n",
            "[Class 1] Epoch 80/150 | D_loss=1.7720 | G_loss=1.5536\n",
            "[Class 1] Epoch 90/150 | D_loss=1.9278 | G_loss=1.3905\n",
            "[Class 1] Epoch 100/150 | D_loss=1.7722 | G_loss=1.4289\n",
            "[Class 1] Epoch 110/150 | D_loss=1.7042 | G_loss=1.5254\n",
            "[Class 1] Epoch 120/150 | D_loss=1.4573 | G_loss=1.6396\n",
            "[Class 1] Epoch 130/150 | D_loss=1.4458 | G_loss=1.7345\n",
            "[Class 1] Epoch 140/150 | D_loss=1.2797 | G_loss=1.6015\n",
            "[Class 1] Epoch 150/150 | D_loss=1.1638 | G_loss=1.8407\n",
            "\n",
            " Class counts after augmentation: Counter({np.int32(1): 921, np.int32(0): 785})\n",
            "\n",
            " GAN augmentation finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(Counter(y_val_aug))\n",
        "print(Counter(y_ar_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM3lfXxX39KV",
        "outputId": "8643a94c-21d8-4fe1-b46e-8114b6934ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({np.int32(1): 957, np.int32(0): 809})\n",
            "Counter({np.int32(1): 921, np.int32(0): 785})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  Adjacency Matrix Initialization (Gaussian Kernel)\n",
        "# ==========================================\n",
        "def initialize_adjacency_matrix(n_channels=32, lambda_threshold=5.0, theta=2.0):\n",
        "    \"\"\"\n",
        "    Initialize adjacency matrix using Gaussian kernel.\n",
        "    \"\"\"\n",
        "    # Placeholder 3D coordinates for EEG channels\n",
        "    coords_3d = np.array([\n",
        "        [0, 6, 8], [2, 6, 8], [-2, 6, 8], [0, 4, 8],       # Fp1, Fp2, F3, F4\n",
        "        [-3, 4, 6], [3, 4, 6], [-1, 2, 7], [1, 2, 7],       # F7, F8, FC5, FC6\n",
        "        [-2, 1, 6], [2, 1, 6], [-3, 0, 4], [3, 0, 4],       # T7, T8, CP5, CP6\n",
        "        [-1, -1, 5], [1, -1, 5], [0, -2, 4], [0, -3, 3],    # C3, C4, Cz, Pz\n",
        "        [-2, -3, 3], [2, -3, 3], [-3, -4, 2], [3, -4, 2],   # PO3, PO4, Oz, Iz\n",
        "        [-2, 3, 6], [2, 3, 6], [-3, 1, 5], [3, 1, 5],       # F5, F6, C5, C6\n",
        "        [-2, -1, 4], [2, -1, 4], [-1, -3, 3], [1, -3, 3],   # P5, P6, PO7, PO8\n",
        "        [0, -1, 5], [0, 1, 7], [-1, 0, 6], [1, 0, 6]        # FCz, Fz, C3', C4'\n",
        "    ])\n",
        "    W = np.zeros((n_channels, n_channels))\n",
        "\n",
        "    for i in range(n_channels):\n",
        "        for j in range(n_channels):\n",
        "            if i == j:\n",
        "                W[i, j] = 0\n",
        "            else:\n",
        "                dist = euclidean(coords_3d[i], coords_3d[j])\n",
        "                if dist <= lambda_threshold:\n",
        "                    W[i, j] = np.exp(-(dist**2) / (2 * theta**2))\n",
        "                else:\n",
        "                    W[i, j] = 0\n",
        "    return torch.tensor(W, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "#  GNN for Emotion Classification\n",
        "# ==========================================\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "class GNNEmotionClassifier(nn.Module):\n",
        "    def __init__(self, n_channels=32, feat_length=None, hidden_sizes=[50, 28, 7, 2],\n",
        "                 dropout_rates=[0.22, 0.0, 0.0, 0.05], target_node=15):\n",
        "        super().__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.feat_length = feat_length\n",
        "        self.target_node = target_node\n",
        "\n",
        "        # Learnable adjacency matrix\n",
        "        A_init = initialize_adjacency_matrix(n_channels)\n",
        "        self.A = nn.Parameter(A_init.to(device))\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dropouts = nn.ModuleList()\n",
        "\n",
        "        in_features = feat_length\n",
        "        for hidden_size, dropout_rate in zip(hidden_sizes, dropout_rates):\n",
        "            self.layers.append(nn.Linear(in_features, hidden_size))\n",
        "            self.dropouts.append(nn.Dropout(dropout_rate) if dropout_rate > 0 else nn.Identity())\n",
        "            in_features = hidden_size\n",
        "\n",
        "    def forward(self, S):\n",
        "        \"\"\"\n",
        "        Forward pass with graph convolution\n",
        "        \"\"\"\n",
        "        B, C, F = S.shape  # (batch, channels, features)\n",
        "        X = S\n",
        "\n",
        "        for layer, dropout in zip(self.layers, self.dropouts):\n",
        "            # Graph convolution: aggregate neighbor info\n",
        "            A_hat = torch.softmax(self.A, dim=1)          # normalize per node\n",
        "            X = torch.einsum('ij,bjk->bik', A_hat, X)     # aggregate neighbors\n",
        "\n",
        "            B, C, F = X.shape\n",
        "            X_flat = X.reshape(B * C, F)\n",
        "\n",
        "            # Stronger activation for separability\n",
        "            X_flat = torch.relu(layer(X_flat))\n",
        "\n",
        "\n",
        "            X_flat = dropout(X_flat)\n",
        "            X = X_flat.reshape(B, C, -1)\n",
        "        # Output for target node\n",
        "        output = X[:, self.target_node, :]\n",
        "        return output\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Training Function\n",
        "# ==========================================\n",
        "def train_gnn(model, X_train, y_train,\n",
        "              batch_size=100, epochs=400, lr=5e-5,\n",
        "              weight_decay=1e-4):\n",
        "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
        "                                  torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    labels = y_train\n",
        "    classes = np.unique(labels)\n",
        "    class_sample_count = np.array([len(np.where(labels == t)[0]) for t in classes])\n",
        "    weight = 1. / class_sample_count\n",
        "    samples_weight = np.array([weight[t] for t in labels])\n",
        "\n",
        "    samples_weight = torch.from_numpy(samples_weight).double()\n",
        "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "\n",
        "    train_losses, train_accs = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_preds, train_labels = [], []\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "            train_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accs': train_accs\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "# ==========================================\n",
        "# Evaluation on test set\n",
        "# ==========================================\n",
        "def evaluate_gnn(model, X_test, y_test, batch_size=100):\n",
        "    test_dataset = TensorDataset(\n",
        "        torch.tensor(X_test, dtype=torch.float32),\n",
        "        torch.tensor(y_test, dtype=torch.long)\n",
        "    )\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            test_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "            test_labels.extend(y_batch.numpy())\n",
        "\n",
        "    test_acc = accuracy_score(test_labels, test_preds)\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\" Test Accuracy: {test_acc*100:.2f}%\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return {'test_acc': test_acc, 'predictions': test_preds, 'labels': test_labels}\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# Pipeline Integration\n",
        "# ==========================================\n",
        "def run_gnn_pipeline(X_train, y_train, X_test, y_test, target_node=15):\n",
        "    # Initialize model\n",
        "    model = GNNEmotionClassifier(\n",
        "        n_channels=X_train.shape[1],\n",
        "        feat_length=X_train.shape[2],\n",
        "        hidden_sizes=[50,28,7,2],\n",
        "        dropout_rates=[0.22,0.0,0.0,0.05],\n",
        "        target_node=target_node\n",
        "    ).to(device)\n",
        "\n",
        "    print(f\"\\n Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
        "\n",
        "    # Train on full training data\n",
        "    history = train_gnn(model, X_train, y_train)\n",
        "\n",
        "    # Evaluate on test data\n",
        "    results = evaluate_gnn(model, X_test, y_test)\n",
        "\n",
        "    return model, history, results"
      ],
      "metadata": {
        "id": "tmf8MLiqS-lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #X_val_combined = np.vstack([train_features, X_val_aug])\n",
        "    #y_val_combined = np.concatenate([y_val_train, y_val_aug])\n",
        "\n",
        "    #X_ar_combined = np.vstack([train_features, X_ar_aug])\n",
        "    #y_ar_combined = np.concatenate([y_ar_train, y_ar_aug])\n",
        "    #print(f\"\\nCombined Valence dataset: {X_val_combined.shape}, labels: {Counter(y_val_combined)}\")\n",
        "    #print(f\" Combined Arousal dataset: {X_ar_combined.shape}, labels: {Counter(y_ar_combined)}\")\n",
        "\n",
        "    # ===============================\n",
        "    #  Train GNN and Evaluate\n",
        "    # ===============================\n",
        "    print(\"\\n Training GNN for Valence...\")\n",
        "    model_valence, val_history, val_results = run_gnn_pipeline(\n",
        "    X_val_aug,\n",
        "    y_val_aug,\n",
        "    test_features,\n",
        "    y_val_test\n",
        "    )\n",
        "    val_pred = val_results['predictions']\n",
        "\n",
        "\n",
        "    print(\"\\n Training GNN for Arousal...\")\n",
        "    model_arousal, ar_history, ar_results = run_gnn_pipeline(\n",
        "    X_ar_aug,\n",
        "    y_ar_aug,\n",
        "    test_features,\n",
        "    y_ar_test\n",
        "    )\n",
        "    ar_pred = ar_results['predictions']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyPNQ3hscLrX",
        "outputId": "a89c2530-64e6-4e43-ff97-a9b5f292dbeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training GNN for Valence...\n",
            "\n",
            " Model initialized with 8721 parameters\n",
            "Epoch 10/400 | Train Loss: 0.6970, Acc: 0.4994\n",
            "Epoch 20/400 | Train Loss: 0.6750, Acc: 0.6393\n",
            "Epoch 30/400 | Train Loss: 0.6522, Acc: 0.6840\n",
            "Epoch 40/400 | Train Loss: 0.6309, Acc: 0.7027\n",
            "Epoch 50/400 | Train Loss: 0.5984, Acc: 0.8188\n",
            "Epoch 60/400 | Train Loss: 0.5611, Acc: 0.8505\n",
            "Epoch 70/400 | Train Loss: 0.5225, Acc: 0.8635\n",
            "Epoch 80/400 | Train Loss: 0.5189, Acc: 0.8505\n",
            "Epoch 90/400 | Train Loss: 0.4787, Acc: 0.8675\n",
            "Epoch 100/400 | Train Loss: 0.4761, Acc: 0.8647\n",
            "Epoch 110/400 | Train Loss: 0.4670, Acc: 0.8545\n",
            "Epoch 120/400 | Train Loss: 0.4488, Acc: 0.8658\n",
            "Epoch 130/400 | Train Loss: 0.4478, Acc: 0.8618\n",
            "Epoch 140/400 | Train Loss: 0.4081, Acc: 0.8749\n",
            "Epoch 150/400 | Train Loss: 0.3974, Acc: 0.8743\n",
            "Epoch 160/400 | Train Loss: 0.4042, Acc: 0.8539\n",
            "Epoch 170/400 | Train Loss: 0.3565, Acc: 0.8743\n",
            "Epoch 180/400 | Train Loss: 0.3741, Acc: 0.8647\n",
            "Epoch 190/400 | Train Loss: 0.3462, Acc: 0.8754\n",
            "Epoch 200/400 | Train Loss: 0.3705, Acc: 0.8539\n",
            "Epoch 210/400 | Train Loss: 0.3388, Acc: 0.8709\n",
            "Epoch 220/400 | Train Loss: 0.3353, Acc: 0.8709\n",
            "Epoch 230/400 | Train Loss: 0.3283, Acc: 0.8686\n",
            "Epoch 240/400 | Train Loss: 0.3194, Acc: 0.8698\n",
            "Epoch 250/400 | Train Loss: 0.3432, Acc: 0.8545\n",
            "Epoch 260/400 | Train Loss: 0.3065, Acc: 0.8811\n",
            "Epoch 270/400 | Train Loss: 0.3077, Acc: 0.8709\n",
            "Epoch 280/400 | Train Loss: 0.3287, Acc: 0.8584\n",
            "Epoch 290/400 | Train Loss: 0.3122, Acc: 0.8760\n",
            "Epoch 300/400 | Train Loss: 0.3225, Acc: 0.8664\n",
            "Epoch 310/400 | Train Loss: 0.3161, Acc: 0.8647\n",
            "Epoch 320/400 | Train Loss: 0.3117, Acc: 0.8692\n",
            "Epoch 330/400 | Train Loss: 0.3000, Acc: 0.8788\n",
            "Epoch 340/400 | Train Loss: 0.2880, Acc: 0.8822\n",
            "Epoch 350/400 | Train Loss: 0.3062, Acc: 0.8749\n",
            "Epoch 360/400 | Train Loss: 0.2975, Acc: 0.8732\n",
            "Epoch 370/400 | Train Loss: 0.3064, Acc: 0.8715\n",
            "Epoch 380/400 | Train Loss: 0.2899, Acc: 0.8743\n",
            "Epoch 390/400 | Train Loss: 0.2920, Acc: 0.8794\n",
            "Epoch 400/400 | Train Loss: 0.3246, Acc: 0.8488\n",
            "\n",
            "==================================================\n",
            " Test Accuracy: 78.91%\n",
            "==================================================\n",
            "\n",
            " Training GNN for Arousal...\n",
            "\n",
            " Model initialized with 8721 parameters\n",
            "Epoch 10/400 | Train Loss: 0.6888, Acc: 0.6166\n",
            "Epoch 20/400 | Train Loss: 0.6834, Acc: 0.6618\n",
            "Epoch 30/400 | Train Loss: 0.6763, Acc: 0.7063\n",
            "Epoch 40/400 | Train Loss: 0.6637, Acc: 0.7181\n",
            "Epoch 50/400 | Train Loss: 0.6495, Acc: 0.7321\n",
            "Epoch 60/400 | Train Loss: 0.6261, Acc: 0.7421\n",
            "Epoch 70/400 | Train Loss: 0.6015, Acc: 0.7526\n",
            "Epoch 80/400 | Train Loss: 0.5641, Acc: 0.7761\n",
            "Epoch 90/400 | Train Loss: 0.5465, Acc: 0.7943\n",
            "Epoch 100/400 | Train Loss: 0.5181, Acc: 0.8148\n",
            "Epoch 110/400 | Train Loss: 0.5242, Acc: 0.8113\n",
            "Epoch 120/400 | Train Loss: 0.5018, Acc: 0.8118\n",
            "Epoch 130/400 | Train Loss: 0.4920, Acc: 0.8353\n",
            "Epoch 140/400 | Train Loss: 0.4943, Acc: 0.8458\n",
            "Epoch 150/400 | Train Loss: 0.4955, Acc: 0.8359\n",
            "Epoch 160/400 | Train Loss: 0.4942, Acc: 0.8277\n",
            "Epoch 170/400 | Train Loss: 0.4923, Acc: 0.8394\n",
            "Epoch 180/400 | Train Loss: 0.4804, Acc: 0.8365\n",
            "Epoch 190/400 | Train Loss: 0.4612, Acc: 0.8581\n",
            "Epoch 200/400 | Train Loss: 0.4679, Acc: 0.8370\n",
            "Epoch 210/400 | Train Loss: 0.4725, Acc: 0.8359\n",
            "Epoch 220/400 | Train Loss: 0.4856, Acc: 0.8470\n",
            "Epoch 230/400 | Train Loss: 0.4736, Acc: 0.8564\n",
            "Epoch 240/400 | Train Loss: 0.4917, Acc: 0.8517\n",
            "Epoch 250/400 | Train Loss: 0.4873, Acc: 0.8435\n",
            "Epoch 260/400 | Train Loss: 0.4827, Acc: 0.8394\n",
            "Epoch 270/400 | Train Loss: 0.4676, Acc: 0.8505\n",
            "Epoch 280/400 | Train Loss: 0.4809, Acc: 0.8423\n",
            "Epoch 290/400 | Train Loss: 0.4664, Acc: 0.8558\n",
            "Epoch 300/400 | Train Loss: 0.4546, Acc: 0.8429\n",
            "Epoch 310/400 | Train Loss: 0.4796, Acc: 0.8564\n",
            "Epoch 320/400 | Train Loss: 0.4653, Acc: 0.8581\n",
            "Epoch 330/400 | Train Loss: 0.4673, Acc: 0.8458\n",
            "Epoch 340/400 | Train Loss: 0.4673, Acc: 0.8447\n",
            "Epoch 350/400 | Train Loss: 0.4652, Acc: 0.8546\n",
            "Epoch 360/400 | Train Loss: 0.4772, Acc: 0.8505\n",
            "Epoch 370/400 | Train Loss: 0.4512, Acc: 0.8593\n",
            "Epoch 380/400 | Train Loss: 0.4645, Acc: 0.8570\n",
            "Epoch 390/400 | Train Loss: 0.4625, Acc: 0.8546\n",
            "Epoch 400/400 | Train Loss: 0.4632, Acc: 0.8482\n",
            "\n",
            "==================================================\n",
            " Test Accuracy: 74.22%\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}